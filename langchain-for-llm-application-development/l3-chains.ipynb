{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chains in LangChain\n",
    "\n",
    "## Outline\n",
    "\n",
    "* LLMChain\n",
    "* Sequential Chains\n",
    "  * SimpleSequentialChain\n",
    "  * SequentialChain\n",
    "* Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# account for deprecation of LLM model\n",
    "import datetime\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "target_date = datetime.date(2024, 6, 12)\n",
    "\n",
    "# Set the model variable based on the current date\n",
    "if current_date > target_date:\n",
    "    llm_model = \"gpt-3.5-turbo\"\n",
    "else:\n",
    "    llm_model = \"gpt-3.5-turbo-0301\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Product': {0: 'Queen Size Sheet Set',\n",
    "  1: 'Waterproof Phone Pouch',\n",
    "  2: 'Luxury Air Mattress',\n",
    "  3: 'Pillows Insert',\n",
    "  4: 'Milk Frother Handheld\\n',\n",
    "  5: \"L'Or Espresso Caf√©\\xa0\\n\",\n",
    "  6: 'Hervidor de Agua El√©ctrico'},\n",
    " 'Review': {0: 'I ordered a king size set. My only criticism would be that I wish seller would offer the king size set with 4 pillowcases. I separately ordered a two pack of pillowcases so I could have a total of four. When I saw the two packages, it looked like the color did not exactly match. Customer service was excellent about sending me two more pillowcases so I would have four that matched. Excellent! For the cost of these sheets, I am satisfied with the characteristics and coolness of the sheets.',\n",
    "  1: 'I loved the waterproof sac, although the opening was made of a hard plastic. I don‚Äôt know if that would break easily. But I couldn‚Äôt turn my phone on, once it was in the pouch.',\n",
    "  2: \"This mattress had a small hole in the top of it (took forever to find where it was), and the patches that they provide did not work, maybe because it's the top of the mattress where it's kind of like fabric and a patch won't stick. Maybe I got unlucky with a defective mattress, but where's quality assurance for this company? That flat out should not happen. Emphasis on flat. Cause that's what the mattress was. Seriously horrible experience, ruined my friend's stay with me. Then they make you ship it back instead of just providing a refund, which is also super annoying to pack up an air mattress and take it to the UPS store. This company is the worst, and this mattress is the worst.\",\n",
    "  3: 'This is the best throw pillow fillers on Amazon. I‚Äôve tried several others, and they‚Äôre all cheap and flat no matter how much fluffing you do. Once you toss these in the dryer after you remove them from the vacuum sealed shipping material, they fluff up great',\n",
    "  4: \"\\xa0I loved this product. But they only seem to last a few months. The company was great replacing the first one (the frother falls out of the handle and can't be fixed). The after 4 months my second one did the same. I only use the frother for coffee once a day. It's not overuse or abuse. I'm very disappointed and will look for another. As I understand they will only replace once. Anyway, if you have one good luck.\",\n",
    "  5: \"Je trouve le go√ªt m√©diocre. La mousse ne tient pas, c'est bizarre. J'ach√®te les m√™mes dans le commerce et le go√ªt est bien meilleur...\\nVieux lot ou contrefa√ßon !?\",\n",
    "  6: 'Est√° lu bonita calienta muy r√°pido, es muy funcional, solo falta ver cu√°nto dura, solo llevo 3 d√≠as en funcionamiento.'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Queen Size Sheet Set</td>\n",
       "      <td>I ordered a king size set. My only criticism w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waterproof Phone Pouch</td>\n",
       "      <td>I loved the waterproof sac, although the openi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luxury Air Mattress</td>\n",
       "      <td>This mattress had a small hole in the top of i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pillows Insert</td>\n",
       "      <td>This is the best throw pillow fillers on Amazo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milk Frother Handheld\\n</td>\n",
       "      <td>I loved this product. But they only seem to l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Product                                             Review\n",
       "0     Queen Size Sheet Set  I ordered a king size set. My only criticism w...\n",
       "1   Waterproof Phone Pouch  I loved the waterproof sac, although the openi...\n",
       "2      Luxury Air Mattress  This mattress had a small hole in the top of i...\n",
       "3           Pillows Insert  This is the best throw pillow fillers on Amazo...\n",
       "4  Milk Frother Handheld\\n  ¬†I loved this product. But they only seem to l..."
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9, model=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Queen Comfort Co.'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = \"Queen Size Sheet Set\"\n",
    "chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9, model=llm_model)\n",
    "\n",
    "# prompt template 1\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")\n",
    "\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 2\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a 20 words description for the following \\\n",
    "    company:{company_name}\"\n",
    ")\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
    "                                             verbose=True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mRoyal Linens\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mRoyal Linens is a premium bedding and linen company that produces luxurious and comfortable products with attention to detail and quality.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Royal Linens is a premium bedding and linen company that produces luxurious and comfortable products with attention to detail and quality.'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_simple_chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9, model=llm_model)\n",
    "\n",
    "# prompt template 1: translate to english\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following review to english:\"\n",
    "    \"\\n\\n{Review}\"\n",
    ")\n",
    "# chain 1: input= Review and output= English_Review\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     output_key=\"English_Review\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Can you summarize the following review in 1 sentence:\"\n",
    "    \"\\n\\n{English_Review}\"\n",
    ")\n",
    "# chain 2: input= English_Review and output= summary\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key=\"summary\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 3: translate to english\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What language is the following review:\\n\\n{Review}\"\n",
    ")\n",
    "# chain 3: input= Review and output= language\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
    "                       output_key=\"language\"\n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 4: follow up message\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a follow up response to the following \"\n",
    "    \"summary in the specified language:\"\n",
    "    \"\\n\\nSummary: {summary}\\n\\nLanguage: {language}\"\n",
    ")\n",
    "# chain 4: input= summary, language and output= followup_message\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
    "                      output_key=\"followup_message\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_chain: input= Review \n",
    "# and output= English_Review,summary, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"Review\"],\n",
    "    output_variables=[\"English_Review\", \"summary\",\"followup_message\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Review': \"Je trouve le go√ªt m√©diocre. La mousse ne tient pas, c'est bizarre. J'ach√®te les m√™mes dans le commerce et le go√ªt est bien meilleur...\\nVieux lot ou contrefa√ßon !?\",\n",
       " 'English_Review': '\"I find the taste mediocre. The foam doesn\\'t hold, it\\'s weird. I buy the same ones in stores and the taste is much better... Old batch or counterfeit!?\"',\n",
       " 'summary': \"The reviewer found the taste of the product to be mediocre and suspected that it may be an old batch or counterfeit as the foam didn't hold well.\",\n",
       " 'followup_message': \"R√©ponse : Le critique a trouv√© le go√ªt du produit moyen et a suspect√© qu'il pourrait s'agir d'un lot ancien ou contrefait car la mousse ne tenait pas bien.\"}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = df.Review[5]\n",
    "overall_chain(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RouterChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise\\\n",
    "and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit\\\n",
    "that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. \\\n",
    "You are great at answering math questions. \\\n",
    "You are so good because you are able to break down \\\n",
    "hard problems into their component parts, \n",
    "answer the component parts, and then put them together\\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "history_template = \"\"\"You are a very good historian. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods. \\\n",
    "You have the ability to think, reflect, debate, discuss and \\\n",
    "evaluate the past. You have a respect for historical evidence\\\n",
    "and the ability to make use of it to support your explanations \\\n",
    "and judgements.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "computerscience_template = \"\"\" You are a successful computer scientist.\\\n",
    "You have a passion for creativity, collaboration,\\\n",
    "forward-thinking, confidence, strong problem-solving capabilities,\\\n",
    "understanding of theories and algorithms, and excellent communication \\\n",
    "skills. You are great at answering coding questions. \\\n",
    "You are so good because you know how to solve a problem by \\\n",
    "describing the solution in imperative steps \\\n",
    "that a machine can easily interpret and you know how to \\\n",
    "choose a solution that has a good balance between \\\n",
    "time complexity and space complexity. \n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\", \n",
    "        \"description\": \"Good for answering questions about physics\", \n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\", \n",
    "        \"description\": \"Good for answering math questions\", \n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"History\", \n",
    "        \"description\": \"Good for answering history questions\", \n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"computer science\", \n",
    "        \"description\": \"Good for answering computer science questions\", \n",
    "        \"prompt_template\": computerscience_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain  \n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain, verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "physics: {'input': 'What is black body radiation?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Black body radiation refers to the electromagnetic radiation emitted by a perfect black body, which is an object that absorbs all radiation that falls on it and emits radiation at all wavelengths. The radiation emitted by a black body depends only on its temperature and follows a specific distribution known as Planck's law. This type of radiation is important in understanding the behavior of stars, as well as in the development of technologies such as incandescent light bulbs and infrared cameras.\""
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"What is black body radiation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "math: {'input': 'what is 2 + 2'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'As an AI language model, I can answer this question easily. The answer to 2 + 2 is 4.'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"what is 2 + 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "None: {'input': 'Why does every cell in our body contain DNA?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Every cell in our body contains DNA because DNA carries the genetic information that determines the characteristics and functions of each cell. DNA contains the instructions for the synthesis of proteins, which are essential for the structure and function of cells. Additionally, DNA is responsible for the transmission of genetic information from one generation to the next. Therefore, every cell in our body needs DNA to carry out its specific functions and to maintain the integrity of the organism as a whole.'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Why does every cell in our body contain DNA?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment on your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mexican.\n",
      "Bagels.\n",
      "Seafood.\n"
     ]
    }
   ],
   "source": [
    "# LLMChain\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.9, model=llm_model)\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"What type of cuisine is {city} most famous for? Return a one word response.\"\n",
    ")\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "city_1 = 'San Diego'\n",
    "city_2 = 'New York'\n",
    "city_3 = 'Jacksonville'\n",
    "print(chain.run(city_1))\n",
    "print(chain.run(city_2))\n",
    "print(chain.run(city_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mMexican.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m1. Tacos\n",
      "2. Enchiladas\n",
      "3. Quesadillas\n",
      "4. Guacamole\n",
      "5. Chiles Rellenos\u001b[0m\n",
      "\u001b[38;5;200m\u001b[1;3mTacos, oh how I adore\n",
      "The way you fill me up and more\n",
      "Your crispy shells and seasoned beef\n",
      "Are all I need to find relief\n",
      "\n",
      "Enchiladas, wrapped with care\n",
      "Tender meat and sauce so rare\n",
      "Baked to perfection, cheese on top\n",
      "You make my taste buds never stop\n",
      "\n",
      "Quesadillas, ooey and gooey\n",
      "Melting cheese and chicken truly\n",
      "Folded in a tortilla nice and warm\n",
      "Making my hunger forever calm\n",
      "\n",
      "Guacamole, green and fresh\n",
      "A perfect dip, I must confess\n",
      "Ripe avocados and spicy kick\n",
      "My heart you've always managed to pick\n",
      "\n",
      "Chiles Rellenos, stuffed with flair\n",
      "Peppers and cheese, a lovely pair\n",
      "Crispy on the outside, soft within\n",
      "You're a dish I can't help but grin\n",
      "\n",
      "Oh Mexican cuisine, how you delight\n",
      "My senses with every bite\n",
      "Tacos, enchiladas, quesadillas galore\n",
      "Guacamole and chiles rellenos, you are truly adored.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Tacos, oh how I adore\\nThe way you fill me up and more\\nYour crispy shells and seasoned beef\\nAre all I need to find relief\\n\\nEnchiladas, wrapped with care\\nTender meat and sauce so rare\\nBaked to perfection, cheese on top\\nYou make my taste buds never stop\\n\\nQuesadillas, ooey and gooey\\nMelting cheese and chicken truly\\nFolded in a tortilla nice and warm\\nMaking my hunger forever calm\\n\\nGuacamole, green and fresh\\nA perfect dip, I must confess\\nRipe avocados and spicy kick\\nMy heart you've always managed to pick\\n\\nChiles Rellenos, stuffed with flair\\nPeppers and cheese, a lovely pair\\nCrispy on the outside, soft within\\nYou're a dish I can't help but grin\\n\\nOh Mexican cuisine, how you delight\\nMy senses with every bite\\nTacos, enchiladas, quesadillas galore\\nGuacamole and chiles rellenos, you are truly adored.\""
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SimpleSequentialChain\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.9, model=llm_model)\n",
    "\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What type of cuisine is {city} most famous for? Return a one word response.\"\n",
    ")\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)\n",
    "\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What are five popular dishes in {cusine} food?\"\n",
    ")\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)\n",
    "\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a poem about the following dishes: {popular_dishes}\"\n",
    ")\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt)\n",
    "\n",
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two, chain_three],\n",
    "                                             verbose=True\n",
    "                                            )\n",
    "\n",
    "overall_simple_chain.run(\"San Diego\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'business': 'Nike',\n",
       " 'business_description': \"Nike is a multinational corporation that designs, develops, and sells athletic apparel, footwear, equipment, and accessories. It is one of the world's largest suppliers of athletic shoes and apparel and has partnerships with numerous professional athletes and sports teams. Nike has a strong brand identity and is known for its innovative designs, marketing campaigns, and commitment to sustainability.\",\n",
       " 'demographics': \"The primary age and gender demographic target audience for Nike is typically between 18-40 years old and includes both male and female consumers who are interested in athletics, sports, fitness, and lifestyle products. Nike's products are also marketed towards athletes, sports enthusiasts, and active individuals who are inspired by the company's brand mission and values.\",\n",
       " 'target_audience': 'Nike caters to young and active adults who value physical activity, sports, and fashion. With a wide range of athletic apparel, footwear, equipment, and accessories, Nike aims to offer something for everyone. Their brand identity is built on innovation, sustainability, and support for professional athletes and sports teams, making Nike a go-to choice for those who are passionate about sports and fitness.',\n",
       " 'facebook_post': \"Attention all young and active adults! üî•üèÉ\\u200d‚ôÇÔ∏èüèãÔ∏è\\u200d‚ôÄÔ∏è If you value physical activity, sports, and fashion, then Nike has got you covered! With a wide range of athletic apparel, footwear, equipment, and accessories, we offer something for everyone. Our brand identity is built on innovation, sustainability, and support for professional athletes and sports teams, making us a go-to choice for those who are passionate about sports and fitness. üí™üëüüèÄ Don't miss out on the opportunity to achieve your goals and look amazing while doing it. Come check out our latest collection today! #JustDoIt #Nike #Athletics #Sports #Fitness #Fashion #Innovation #Sustainability #ProfessionalAthletes #SportsTeams #Passionate #Goals #Amazing #Collection\"}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SequentialChain\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.9, model=llm_model)\n",
    "\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a three sentence description of the following business:\"\n",
    "    \"\\n\\n{business}\"\n",
    ")\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     output_key=\"business_description\"\n",
    "                    )\n",
    "\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Define the primary age and gender demographic target audience for the following business:\"\n",
    "    \"\\n\\n{business_description}\"\n",
    ")\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key=\"demographics\"\n",
    "                    )\n",
    "\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Create a three sentence description for a target audience of {business}, \"\n",
    "    \"that is described by {business_description}, \"\n",
    "    \"where the target audience's demographics are as follows: {demographics}\"\n",
    ")\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
    "                       output_key=\"target_audience\"\n",
    "                      )\n",
    "\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a facebook advertisement for {business}\"\n",
    "    \"who is trying to reach the following target audience: {target_audience}\"\n",
    "    \"that is of the following demographics {demographics}.\"\n",
    "    \"Make sure to use emojis in the post.\"\n",
    ")\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
    "                      output_key=\"facebook_post\"\n",
    "                     )\n",
    "\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"business\"],\n",
    "    output_variables=[\"business_description\", \"demographics\", \"target_audience\", \"facebook_post\"],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "overall_chain(\"Nike\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "fitness trainer: {'input': 'What are some good back exercises?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "There are many effective back exercises that can help strengthen and tone the muscles in your back. Some of the best exercises include:\n",
      "\n",
      "1. Pull-ups or chin-ups\n",
      "2. Lat pulldowns\n",
      "3. Seated cable rows\n",
      "4. Bent-over barbell rows\n",
      "5. T-bar rows\n",
      "6. Dumbbell rows\n",
      "7. Back extensions\n",
      "8. Deadlifts\n",
      "9. Good mornings\n",
      "10. Reverse flyes\n",
      "\n",
      "It's important to choose exercises that target all areas of your back, including your upper, middle, and lower back muscles. Varying your exercises and incorporating different equipment can also help keep your workouts challenging and effective. As always, be sure to use proper form and start with lighter weights before progressing to heavier weights to avoid injury.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "outdoor enthusiast: {'input': 'Where can I find information about the longest hiking trail in the US?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The longest hiking trail in the US is the Pacific Crest Trail, which spans 2,650 miles from Mexico to Canada through California, Oregon, and Washington. You can find more information about the trail, including maps, permits, and trail conditions, on the Pacific Crest Trail Association website.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "travel agent: {'input': 'Which Hawaiian island is best for whale watching?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Maui is considered the best Hawaiian island for whale watching. The waters surrounding Maui are home to thousands of humpback whales during the winter months, and there are many whale watching tours available on the island.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "machine learning expert: {'input': 'Can you explain logistic regression in one sentence?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Logistic regression is a statistical method used to analyze and model the relationship between a binary dependent variable and one or more independent variables.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "None: {'input': 'What day of the year is Memorial Day?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "As an AI language model, I don't have access to the current year's calendar. However, Memorial Day is observed on the last Monday of May each year in the United States.\n"
     ]
    }
   ],
   "source": [
    "# RouterChain\n",
    "\n",
    "fitness_trainer_template = \"\"\"You are an experienced fitness trainer. \\\n",
    "You possess a deep understanding of human anatomy, physiology, and the principles of fitness and nutrition. \\\n",
    "You're skilled in creating personalized workout plans that are effective, safe, and tailored to individual needs and goals. \\\n",
    "Your expertise also includes motivation and lifestyle coaching to help individuals maintain a healthy, active lifestyle. \\\n",
    "You have the patience and communication skills to explain exercises clearly and to encourage progress, while always being mindful of safety and individual limitations.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "outdoor_enthusiast_template = \"\"\"You are a passionate outdoor enthusiast. \\\n",
    "You have extensive knowledge of various outdoor activities, including hiking, camping, mountain biking, and kayaking. \\\n",
    "Your experiences have equipped you with a wealth of information about outdoor gear, survival skills, and environmental conservation. \\\n",
    "You understand the importance of respecting nature and leaving no trace behind. \\\n",
    "Your enthusiasm is infectious, and you're excellent at providing tips, tricks, and advice for others looking to explore and enjoy the great outdoors.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "travel_agent_template = \"\"\"You are a seasoned travel agent. \\\n",
    "You possess a vast knowledge of global destinations, cultures, and travel logistics. \\\n",
    "Your expertise includes planning itineraries, understanding the best travel deals, and providing tailored recommendations for various types of travelers. \\\n",
    "You're skilled in making travel stress-free and enjoyable, taking into account clients' preferences, budget, and unique needs. \\\n",
    "Your passion for travel and commitment to customer satisfaction make you an invaluable guide in creating memorable travel experiences.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "machine_learning_expert_template = \"\"\"You are a highly skilled machine learning expert. \\\n",
    "You have a deep understanding of algorithms, data structures, statistics, and programming. \\\n",
    "Your expertise encompasses various aspects of machine learning, including supervised and unsupervised learning, neural networks, and deep learning. \\\n",
    "You're adept at analyzing complex data sets, identifying patterns, and applying machine learning techniques to solve real-world problems. \\\n",
    "You can clearly explain complex concepts and are always up-to-date with the latest advancements in the field.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"fitness trainer\",\n",
    "        \"description\": \"Good for answering fitness and health questions\",\n",
    "        \"prompt_template\": fitness_trainer_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"outdoor enthusiast\",\n",
    "        \"description\": \"Good for answering questions about outdoor activities\",\n",
    "        \"prompt_template\": outdoor_enthusiast_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"travel agent\",\n",
    "        \"description\": \"Good for answering travel and vacation-related questions\",\n",
    "        \"prompt_template\": travel_agent_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"machine learning expert\",\n",
    "        \"description\": \"Good for answering questions about machine learning\",\n",
    "        \"prompt_template\": machine_learning_expert_template\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=llm_model)\n",
    "\n",
    "\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain  \n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "\n",
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)\n",
    "\n",
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\"\n",
    "\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)\n",
    "\n",
    "chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain, verbose=True\n",
    "                        )\n",
    "\n",
    "\n",
    "print(chain.run(\"What are some good back exercises?\"))\n",
    "print(chain.run(\"Where is the longest hiking trail in the US?\"))\n",
    "print(chain.run(\"Which Hawaiian island is best for whale watching?\"))\n",
    "print(chain.run(\"Explain logisitic regression in one sentence.\"))\n",
    "print(chain.run(\"What day of the year is Memorial Day?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
